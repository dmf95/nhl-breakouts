{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -1- Active player scrape\n",
    "* Scraping capfriendly for active player data\n",
    "* First, we scrap the entire pool of \"active\" players\n",
    "* Then, we scrape by team for maximal coverage\n",
    "* We finish this section off by appending them and removing any dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -1.1- All active players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 2 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 3 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 4 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 5 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 6 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 7 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 8 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 9 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 10 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 11 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 12 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 13 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 14 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 15 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 16 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 17 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 18 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 19 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 20 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 21 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 22 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 23 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 24 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 25 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 26 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 27 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 28 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 29 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 30 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 31 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-b88c026a47c5>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 32 scraped successfully.\n",
      "Active player data scraped and stored as a pandas dataframe: cap_data_clean.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # Specify the path to Chromedriver (replace with your actual path)\n",
    "    chromedriver_path = 'C:/Users/domen/Downloads/chromedriver_win32/chromedriver.exe'\n",
    "\n",
    "    # Create Chrome options\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')  # Optional: Run headless (without opening a browser window)\n",
    "\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # URL pattern for the pages\n",
    "    url_pattern = 'https://www.capfriendly.com/browse/active?stats-season=2023&age-calculation-date=today&display=signing-team,draft,signing-status,expiry-year,performance-bonus,signing-bonus,caphit-percent,aav,length,minors-salary,base-salary,type,signing-age,signing-date,arbitration,extension&hide=position,handed,skater-stats,goalie-stats&pg={}'\n",
    "\n",
    "    # Initialize an empty DataFrame to store the data\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Loop through all pages (32 pages)\n",
    "    for page_number in range(1, 33):\n",
    "        try:\n",
    "            # Load the page in the WebDriver\n",
    "            driver.get(url_pattern.format(page_number))\n",
    "\n",
    "            # Wait for the page to load (you may need to adjust the sleep time)\n",
    "            time.sleep(5)  # Wait for 5 seconds to allow the page to load\n",
    "\n",
    "            # Get the HTML content of the page\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Parse the HTML content with BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Find the table containing the data\n",
    "            table = soup.find('table')\n",
    "\n",
    "            # Read the table data into a DataFrame\n",
    "            data = pd.read_html(str(table))[0]\n",
    "\n",
    "            # Concatenate the data to the main DataFrame\n",
    "            all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "            print(f\"Page {page_number} scraped successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while scraping page {page_number}: {e}\")\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create copy of data\n",
    "    cap_data = all_data.copy()\n",
    "\n",
    "    # Split the 'DRAFTED' column into four new columns using regular expressions\n",
    "    draft_split = cap_data['DRAFTED'].str.extract(r'(\\d+) - Round (\\d+) - (\\d{4}) \\(([^)]+)\\)')\n",
    "    draft_split.columns = ['DRAFT_ROUND', 'DRAFT_PICK', 'DRAFT_YEAR', 'DRAFT_TEAM']\n",
    "\n",
    "    # Add the new columns to your DataFrame\n",
    "    cap_data = pd.concat([cap_data, draft_split], axis=1)\n",
    "\n",
    "    # Fix the player name\n",
    "    cap_data['PLAYER'] = cap_data['PLAYER'].str.split('.').str[1:].str.join('').str.strip()\n",
    "\n",
    "    # Function to attempt parsing in different date formats\n",
    "    def parse_date(date_str):\n",
    "        formats = [\"%b. %d, %Y\", \"%b %d, %Y\", \"%b. %d, %Y\", \"%b %d, %Y\"]\n",
    "        for date_format in formats:\n",
    "            try:\n",
    "                return pd.to_datetime(date_str, format=date_format).strftime(\"%b. %d, %Y\")  # Format as string\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    # Function to format values\n",
    "    def format_value(value):\n",
    "        # Remove '$' and ',' and convert to float\n",
    "        value_float = float(value.replace('$', '').replace(',', ''))\n",
    "        if value_float >= 1000000:\n",
    "            return f\"${value_float / 1000000:.2f}M\"\n",
    "        else:\n",
    "            return f\"${value_float / 1000:.1f}K\"\n",
    "\n",
    "    # Format column names to lowercase and replace spaces and periods with underscores\n",
    "    cap_data.columns = [col.lower().replace('.', '_').replace(' ', '_').replace('__', '_') for col in cap_data.columns]\n",
    "\n",
    "    # Replace checkmark with 1 or 0\n",
    "    columns_with_checkmark = cap_data.columns[cap_data.isin(['✔']).any()]\n",
    "    for column in columns_with_checkmark:\n",
    "        cap_data[column] = cap_data[column].apply(lambda x: 1 if x == '✔' else 0)\n",
    "\n",
    "    # Function to replace special characters found in player_full_name\n",
    "    def replace_special_chars(input_str):\n",
    "        special_chars = {\n",
    "            'á': 'a', 'Á': 'A', 'ä': 'a', 'Ä': 'A', 'é': 'e', 'É': 'E', 'è': 'e', 'È': 'E', 'ê': 'e', 'Ê': 'E',\n",
    "            'í': 'i', 'Í': 'I', 'ï': 'i', 'Ï': 'I', 'ó': 'o', 'Ó': 'O', 'ö': 'o', 'Ö': 'O', 'ô': 'o', 'Ô': 'O',\n",
    "            'ú': 'u', 'Ú': 'U', 'ü': 'u', 'Ü': 'U', 'û': 'u', 'Û': 'U', 'ñ': 'n', 'Ñ': 'N', 'ç': 'c', 'Ç': 'C',\n",
    "            'ß': 'ss', 'Æ': 'AE', 'æ': 'ae', 'Ø': 'O', 'ø': 'o', 'ł': 'l', 'Ł': 'L', 'ń': 'n', 'Ń': 'N',\n",
    "            'ś': 's', 'Ś': 'S', 'ć': 'c', 'Ć': 'C', 'ź': 'z', 'Ź': 'Z', 'ż': 'z', 'Ż': 'Z', 'ğ': 'g', 'Ğ': 'G',\n",
    "            'şı': 'si', 'Ş': 'Si', 'ķ': 'k', 'Ķ': 'K', 'š': 's', 'Š': 'S', 'č': 'c', 'Č': 'C', 'ž': 'z', 'Ž': 'Z',\n",
    "            'ň': 'n', 'Ň': 'N', 'ř': 'r', 'Ř': 'R', 'ý': 'y', 'Ý': 'Y', 'ů': 'u', 'Ů': 'U', 'ţ': 't', 'Ţ': 'T',\n",
    "            'ă': 'a', 'Ă': 'A', 'ş': 's', 'Ş': 'S', 'ď': 'd', 'Ď': 'D', 'ř': 'r', 'Ř': 'R', 'ť': 't', 'Ť': 'T',\n",
    "            'ĺ': 'l', 'Ĺ': 'L', 'ć': 'c', 'Ć': 'C', 'đ': 'd', 'Đ': 'D', 'ŕ': 'r', 'Ŕ': 'R', 'ľ': 'l', 'Ľ': 'L',\n",
    "            'ŝ': 's', 'Ŝ': 'S', 'ĥ': 'h', 'Ĥ': 'H', 'ĵ': 'j', 'Ĵ': 'J', 'ŵ': 'w', 'Ŵ': 'W', 'ŷ': 'y', 'Ŷ': 'Y',\n",
    "            'ẑ': 'z', 'Ẑ': 'Z', 'ơ': 'o', 'Ơ': 'O', 'ī': 'i', 'Ī': 'I', 'ū': 'u', 'Ū': 'U', 'ț': 't', 'Ț': 'T',\n",
    "            'ș': 's', 'Ș': 'S'\n",
    "        }\n",
    "        # Use a regular expression to match and replace special characters\n",
    "        pattern = re.compile(\"|\".join(map(re.escape, special_chars.keys())))\n",
    "        return pattern.sub(lambda match: special_chars[match.group(0)], input_str)\n",
    "\n",
    "    # Assuming you have a DataFrame named cap_data\n",
    "    cap_data['player_full_name'] = cap_data['player'].apply(replace_special_chars)\n",
    "\n",
    "    # Apply date parsing to \"SIGNING DATE\" column\n",
    "    cap_data['etl_insert_ts'] = pd.Timestamp(datetime.now())\n",
    "    cap_data['years_left'] = cap_data['exp_year'] - cap_data['etl_insert_ts'].dt.year.astype(int)\n",
    "    cap_data['cap_hit_format'] = cap_data['cap_hit'].apply(format_value)\n",
    "    cap_data['aav_format'] = cap_data['aav'].apply(format_value)\n",
    "    cap_data['active_flag'] = 1\n",
    "\n",
    "    # Assuming df is your DataFrame and order is the desired column order\n",
    "    desired_order = [\n",
    "        'player_full_name', 'active_flag', 'team', 'age', 'signing_team', 'type', 'extension',\n",
    "        'arb_elig', 'arb_req', 'clause', 'signing', 'expiry', 'salary', 'base_salary',\n",
    "        'minors', 's_bonus', 'p_bonus', 'drafted', 'draft_round', 'draft_pick',\n",
    "        'draft_year', 'draft_team', 'signing_age', 'signing_date', 'length',\n",
    "        'exp_year', 'years_left', 'cap_hit', 'cap_hit_format', 'cap_hit_%', 'aav',\n",
    "        'aav_format', 'etl_insert_ts']\n",
    "\n",
    "    # Reorder the columns\n",
    "    cap_data_clean = cap_data[desired_order]\n",
    "    print(\"Active player data scraped and stored as a pandas dataframe: cap_data_clean.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -1.2- Active players by team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team ducks scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team coyotes scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team bruins scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team sabres scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team flames scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team hurricanes scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team blackhawks scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team avalanche scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team bluejackets scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team stars scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team redwings scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team oilers scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team panthers scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team kings scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team wild scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team canadiens scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team predators scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team devils scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team islanders scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team rangers scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team senators scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team flyers scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team penguins scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team sharks scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team kraken scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team blues scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team lightning scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team mapleleafs scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team canucks scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team goldenknights scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team capitals scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-628f35b9a17a>:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team jets scraped successfully.\n",
      "Active player data scraped and stored as a pandas dataframe: team_cap_data_clean.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # Specify the path to Chromedriver (replace with your actual path)\n",
    "    chromedriver_path = 'C:/Users/domen/Downloads/chromedriver_win32/chromedriver.exe'\n",
    "\n",
    "    # Create Chrome options\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')  # Optional: Run headless (without opening a browser window)\n",
    "\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # nhl team list\n",
    "    nhl_teams = [\"ducks\",\"coyotes\",\"bruins\",\"sabres\",\"flames\",\"hurricanes\",\"blackhawks\",\"avalanche\",\"bluejackets\",\"stars\",\"redwings\",\"oilers\",\"panthers\",\"kings\",\"wild\",\"canadiens\",\"predators\",\"devils\",\"islanders\",\"rangers\",\"senators\",\"flyers\",\"penguins\",\"sharks\",\"kraken\",\"blues\",\"lightning\",\"mapleleafs\",\"canucks\",\"goldenknights\",\"capitals\",\"jets\"]\n",
    "\n",
    "    # URL pattern for the pages\n",
    "    url_pattern = 'https://www.capfriendly.com/browse/active/2024/caphit/{}?display=signing-team,draft,signing-status,expiry-year,performance-bonus,signing-bonus,caphit-percent,aav,length,minors-salary,base-salary,type,signing-age,signing-date,arbitration,extension&hide=position,handed,skater-stats,goalie-stats'\n",
    "\n",
    "    # Initialize an empty DataFrame to store the data\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Loop through all nhl_teams\n",
    "    for team in nhl_teams:\n",
    "        try:\n",
    "            # Load the page in the WebDriver\n",
    "            driver.get(url_pattern.format(team))\n",
    "\n",
    "            # Wait for the page to load (you may need to adjust the sleep time)\n",
    "            time.sleep(5)  # Wait for 5 seconds to allow the page to load\n",
    "\n",
    "            # Get the HTML content of the page\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Parse the HTML content with BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Find the table containing the data\n",
    "            table = soup.find('table')\n",
    "\n",
    "            # Read the table data into a DataFrame\n",
    "            data = pd.read_html(str(table))[0]\n",
    "\n",
    "            # Concatenate the data to the main DataFrame\n",
    "            all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "            print(f\"Team {team} scraped successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while scraping team {team}: {e}\")\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create copy of data\n",
    "    team_cap_data = all_data.copy()\n",
    "\n",
    "    # Split the 'DRAFTED' column into four new columns using regular expressions\n",
    "    draft_split = team_cap_data['DRAFTED'].str.extract(r'(\\d+) - Round (\\d+) - (\\d{4}) \\(([^)]+)\\)')\n",
    "    draft_split.columns = ['DRAFT_ROUND', 'DRAFT_PICK', 'DRAFT_YEAR', 'DRAFT_TEAM']\n",
    "\n",
    "    # Add the new columns to your DataFrame\n",
    "    team_cap_data = pd.concat([team_cap_data, draft_split], axis=1)\n",
    "\n",
    "    # Fix the player name\n",
    "    team_cap_data['PLAYER'] = team_cap_data['PLAYER'].str.split('.').str[1:].str.join('').str.strip()\n",
    "\n",
    "    # Function to attempt parsing in different date formats\n",
    "    def parse_date(date_str):\n",
    "        formats = [\"%b. %d, %Y\", \"%b %d, %Y\", \"%b. %d, %Y\", \"%b %d, %Y\"]\n",
    "        for date_format in formats:\n",
    "            try:\n",
    "                return pd.to_datetime(date_str, format=date_format).strftime(\"%b. %d, %Y\")  # Format as string\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    # Function to format values\n",
    "    def format_value(value):\n",
    "        # Remove '$' and ',' and convert to float\n",
    "        value_float = float(value.replace('$', '').replace(',', ''))\n",
    "        if value_float >= 1000000:\n",
    "            return f\"${value_float / 1000000:.2f}M\"\n",
    "        else:\n",
    "            return f\"${value_float / 1000:.1f}K\"\n",
    "\n",
    "    # Format column names to lowercase and replace spaces and periods with underscores\n",
    "    team_cap_data.columns = [col.lower().replace('.', '_').replace(' ', '_').replace('__', '_') for col in team_cap_data.columns]\n",
    "\n",
    "    # Replace checkmark with 1 or 0\n",
    "    columns_with_checkmark = team_cap_data.columns[team_cap_data.isin(['✔']).any()]\n",
    "    for column in columns_with_checkmark:\n",
    "        team_cap_data[column] = team_cap_data[column].apply(lambda x: 1 if x == '✔' else 0)\n",
    "\n",
    "    # Function to replace special characters found in player_full_name\n",
    "    def replace_special_chars(input_str):\n",
    "        special_chars = {\n",
    "            'á': 'a', 'Á': 'A', 'ä': 'a', 'Ä': 'A', 'é': 'e', 'É': 'E', 'è': 'e', 'È': 'E', 'ê': 'e', 'Ê': 'E',\n",
    "            'í': 'i', 'Í': 'I', 'ï': 'i', 'Ï': 'I', 'ó': 'o', 'Ó': 'O', 'ö': 'o', 'Ö': 'O', 'ô': 'o', 'Ô': 'O',\n",
    "            'ú': 'u', 'Ú': 'U', 'ü': 'u', 'Ü': 'U', 'û': 'u', 'Û': 'U', 'ñ': 'n', 'Ñ': 'N', 'ç': 'c', 'Ç': 'C',\n",
    "            'ß': 'ss', 'Æ': 'AE', 'æ': 'ae', 'Ø': 'O', 'ø': 'o', 'ł': 'l', 'Ł': 'L', 'ń': 'n', 'Ń': 'N',\n",
    "            'ś': 's', 'Ś': 'S', 'ć': 'c', 'Ć': 'C', 'ź': 'z', 'Ź': 'Z', 'ż': 'z', 'Ż': 'Z', 'ğ': 'g', 'Ğ': 'G',\n",
    "            'şı': 'si', 'Ş': 'Si', 'ķ': 'k', 'Ķ': 'K', 'š': 's', 'Š': 'S', 'č': 'c', 'Č': 'C', 'ž': 'z', 'Ž': 'Z',\n",
    "            'ň': 'n', 'Ň': 'N', 'ř': 'r', 'Ř': 'R', 'ý': 'y', 'Ý': 'Y', 'ů': 'u', 'Ů': 'U', 'ţ': 't', 'Ţ': 'T',\n",
    "            'ă': 'a', 'Ă': 'A', 'ş': 's', 'Ş': 'S', 'ď': 'd', 'Ď': 'D', 'ř': 'r', 'Ř': 'R', 'ť': 't', 'Ť': 'T',\n",
    "            'ĺ': 'l', 'Ĺ': 'L', 'ć': 'c', 'Ć': 'C', 'đ': 'd', 'Đ': 'D', 'ŕ': 'r', 'Ŕ': 'R', 'ľ': 'l', 'Ľ': 'L',\n",
    "            'ŝ': 's', 'Ŝ': 'S', 'ĥ': 'h', 'Ĥ': 'H', 'ĵ': 'j', 'Ĵ': 'J', 'ŵ': 'w', 'Ŵ': 'W', 'ŷ': 'y', 'Ŷ': 'Y',\n",
    "            'ẑ': 'z', 'Ẑ': 'Z', 'ơ': 'o', 'Ơ': 'O', 'ī': 'i', 'Ī': 'I', 'ū': 'u', 'Ū': 'U', 'ț': 't', 'Ț': 'T',\n",
    "            'ș': 's', 'Ș': 'S'\n",
    "        }\n",
    "        # Use a regular expression to match and replace special characters\n",
    "        pattern = re.compile(\"|\".join(map(re.escape, special_chars.keys())))\n",
    "        return pattern.sub(lambda match: special_chars[match.group(0)], input_str)\n",
    "\n",
    "    # Assuming you have a DataFrame named team_cap_data\n",
    "    team_cap_data['player_full_name'] = team_cap_data['player'].apply(replace_special_chars)\n",
    "\n",
    "    # Apply date parsing to \"SIGNING DATE\" column\n",
    "    team_cap_data['etl_insert_ts'] = pd.Timestamp(datetime.now())\n",
    "    team_cap_data['years_left'] = team_cap_data['exp_year'] - team_cap_data['etl_insert_ts'].dt.year.astype(int)\n",
    "    team_cap_data['cap_hit_format'] = team_cap_data['cap_hit'].apply(format_value)\n",
    "    team_cap_data['aav_format'] = team_cap_data['aav'].apply(format_value)\n",
    "    team_cap_data['active_flag'] = 1\n",
    "\n",
    "    # Assuming df is your DataFrame and order is the desired column order\n",
    "    desired_order = [\n",
    "        'player_full_name', 'active_flag', 'team', 'age', 'signing_team', 'type', 'extension',\n",
    "        'arb_elig', 'arb_req', 'clause', 'signing', 'expiry', 'salary', 'base_salary',\n",
    "        'minors', 's_bonus', 'p_bonus', 'drafted', 'draft_round', 'draft_pick',\n",
    "        'draft_year', 'draft_team', 'signing_age', 'signing_date', 'length',\n",
    "        'exp_year', 'years_left', 'cap_hit', 'cap_hit_format', 'cap_hit_%', 'aav',\n",
    "        'aav_format', 'etl_insert_ts']\n",
    "\n",
    "    # Reorder the columns\n",
    "    team_cap_data_clean = team_cap_data[desired_order]\n",
    "    print(\"Active player data scraped and stored as a pandas dataframe: team_cap_data_clean.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -1.3- Union together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have cap_data_clean and team_cap_data_clean DataFrames\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "active_cap_data_clean = pd.concat([cap_data_clean, team_cap_data_clean])\n",
    "\n",
    "# Sort the DataFrame by 'exp_year' in descending order\n",
    "active_cap_data_clean.sort_values(by='exp_year', ascending=False, inplace=True)\n",
    "\n",
    "# Remove duplicate records based on player_full_name and team, keeping the one with the highest 'exp_year'\n",
    "active_cap_data_clean.drop_duplicates(subset=['player_full_name', 'team'], keep='first', inplace=True)\n",
    "\n",
    "# Reset the index if needed\n",
    "active_cap_data_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -2- Free agent player scrape\n",
    "* Scraping capfriendly for free agent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-246-acd9e46c46b4>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-246-acd9e46c46b4>:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  data = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 2 scraped successfully.\n",
      "Free Agent player data scraped and stored as a pandas dataframe: fa_cap_data_clean.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # Specify the path to Chromedriver (replace with your actual path)\n",
    "    chromedriver_path = 'C:/Users/domen/Downloads/chromedriver_win32/chromedriver.exe'\n",
    "\n",
    "    # Create Chrome options\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')  # Optional: Run headless (without opening a browser window)\n",
    "\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # URL pattern for the pages\n",
    "    url_pattern = 'https://www.capfriendly.com/browse/free-agents?stats-season=2023&age-calculation-date=today&display=signing-team,draft,signing-status,expiry-year,performance-bonus,signing-bonus,caphit-percent,aav,length,minors-salary,base-salary,type,signing-age,signing-date,arbitration,extension&hide=position,handed,skater-stats,goalie-stats&pg={}'\n",
    "\n",
    "    # Initialize an empty DataFrame to store the data\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Loop through all pages (2 pages)\n",
    "    for page_number in range(1, 3):\n",
    "        try:\n",
    "            # Load the page in the WebDriver\n",
    "            driver.get(url_pattern.format(page_number))\n",
    "\n",
    "            # Wait for the page to load (you may need to adjust the sleep time)\n",
    "            time.sleep(5)  # Wait for 5 seconds to allow the page to load\n",
    "\n",
    "            # Get the HTML content of the page\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Parse the HTML content with BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Find the table containing the data\n",
    "            table = soup.find('table')\n",
    "\n",
    "            # Read the table data into a DataFrame\n",
    "            data = pd.read_html(str(table))[0]\n",
    "\n",
    "            # Concatenate the data to the main DataFrame\n",
    "            all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "            print(f\"Page {page_number} scraped successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while scraping page {page_number}: {e}\")\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create copy of data\n",
    "    fa_cap_data = all_data.copy()\n",
    "\n",
    "    # Split the 'DRAFTED' column into four new columns using regular expressions\n",
    "    draft_split = fa_cap_data['DRAFTED'].str.extract(r'(\\d+) - Round (\\d+) - (\\d{4}) \\(([^)]+)\\)')\n",
    "    draft_split.columns = ['DRAFT_ROUND', 'DRAFT_PICK', 'DRAFT_YEAR', 'DRAFT_TEAM']\n",
    "\n",
    "    # Add the new columns to your DataFrame\n",
    "    fa_cap_data = pd.concat([fa_cap_data, draft_split], axis=1)\n",
    "\n",
    "    # Fix the player name\n",
    "    fa_cap_data['PLAYER'] = fa_cap_data['PLAYER'].str.split('.').str[1:].str.join('').str.strip()\n",
    "\n",
    "    # Function to attempt parsing in different date formats\n",
    "    def parse_date(date_str):\n",
    "        formats = [\"%b. %d, %Y\", \"%b %d, %Y\", \"%b. %d, %Y\", \"%b %d, %Y\"]\n",
    "        for date_format in formats:\n",
    "            try:\n",
    "                return pd.to_datetime(date_str, format=date_format).strftime(\"%b. %d, %Y\")  # Format as string\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    # Function to format values\n",
    "    def format_value(value):\n",
    "        # Remove '$' and ',' and convert to float\n",
    "        value_float = float(value.replace('$', '').replace(',', ''))\n",
    "        if value_float >= 1000000:\n",
    "            return f\"${value_float / 1000000:.2f}M\"\n",
    "        else:\n",
    "            return f\"${value_float / 1000:.1f}K\"\n",
    "\n",
    "    # Format column names to lowercase and replace spaces and periods with underscores\n",
    "    fa_cap_data.columns = [col.lower().replace('.', '_').replace(' ', '_').replace('__', '_') for col in fa_cap_data.columns]\n",
    "\n",
    "    # Replace checkmark with 1 or 0\n",
    "    columns_with_checkmark = fa_cap_data.columns[fa_cap_data.isin(['✔']).any()]\n",
    "    for column in columns_with_checkmark:\n",
    "        fa_cap_data[column] = fa_cap_data[column].apply(lambda x: 1 if x == '✔' else 0)\n",
    "\n",
    "    # Function to replace special characters found in player_full_name\n",
    "    def replace_special_chars(input_str):\n",
    "        special_chars = {\n",
    "            'á': 'a', 'Á': 'A', 'ä': 'a', 'Ä': 'A', 'é': 'e', 'É': 'E', 'è': 'e', 'È': 'E', 'ê': 'e', 'Ê': 'E',\n",
    "            'í': 'i', 'Í': 'I', 'ï': 'i', 'Ï': 'I', 'ó': 'o', 'Ó': 'O', 'ö': 'o', 'Ö': 'O', 'ô': 'o', 'Ô': 'O',\n",
    "            'ú': 'u', 'Ú': 'U', 'ü': 'u', 'Ü': 'U', 'û': 'u', 'Û': 'U', 'ñ': 'n', 'Ñ': 'N', 'ç': 'c', 'Ç': 'C',\n",
    "            'ß': 'ss', 'Æ': 'AE', 'æ': 'ae', 'Ø': 'O', 'ø': 'o', 'ł': 'l', 'Ł': 'L', 'ń': 'n', 'Ń': 'N',\n",
    "            'ś': 's', 'Ś': 'S', 'ć': 'c', 'Ć': 'C', 'ź': 'z', 'Ź': 'Z', 'ż': 'z', 'Ż': 'Z', 'ğ': 'g', 'Ğ': 'G',\n",
    "            'şı': 'si', 'Ş': 'Si', 'ķ': 'k', 'Ķ': 'K', 'š': 's', 'Š': 'S', 'č': 'c', 'Č': 'C', 'ž': 'z', 'Ž': 'Z',\n",
    "            'ň': 'n', 'Ň': 'N', 'ř': 'r', 'Ř': 'R', 'ý': 'y', 'Ý': 'Y', 'ů': 'u', 'Ů': 'U', 'ţ': 't', 'Ţ': 'T',\n",
    "            'ă': 'a', 'Ă': 'A', 'ş': 's', 'Ş': 'S', 'ď': 'd', 'Ď': 'D', 'ř': 'r', 'Ř': 'R', 'ť': 't', 'Ť': 'T',\n",
    "            'ĺ': 'l', 'Ĺ': 'L', 'ć': 'c', 'Ć': 'C', 'đ': 'd', 'Đ': 'D', 'ŕ': 'r', 'Ŕ': 'R', 'ľ': 'l', 'Ľ': 'L',\n",
    "            'ŝ': 's', 'Ŝ': 'S', 'ĥ': 'h', 'Ĥ': 'H', 'ĵ': 'j', 'Ĵ': 'J', 'ŵ': 'w', 'Ŵ': 'W', 'ŷ': 'y', 'Ŷ': 'Y',\n",
    "            'ẑ': 'z', 'Ẑ': 'Z', 'ơ': 'o', 'Ơ': 'O', 'ī': 'i', 'Ī': 'I', 'ū': 'u', 'Ū': 'U', 'ț': 't', 'Ț': 'T',\n",
    "            'ș': 's', 'Ș': 'S'\n",
    "        }\n",
    "        # Use a regular expression to match and replace special characters\n",
    "        pattern = re.compile(\"|\".join(map(re.escape, special_chars.keys())))\n",
    "        return pattern.sub(lambda match: special_chars[match.group(0)], input_str)\n",
    "\n",
    "    # Assuming you have a DataFrame named fa_cap_data\n",
    "    fa_cap_data['player_full_name'] = fa_cap_data['player'].apply(replace_special_chars)\n",
    "\n",
    "    # Apply date parsing to \"SIGNING DATE\" column\n",
    "    fa_cap_data['etl_insert_ts'] = pd.Timestamp(datetime.now())\n",
    "    fa_cap_data['years_left'] = fa_cap_data['exp_year'] - fa_cap_data['etl_insert_ts'].dt.year.astype(int)\n",
    "    fa_cap_data['cap_hit_format'] = fa_cap_data['cap_hit'].apply(format_value)\n",
    "    fa_cap_data['aav_format'] = fa_cap_data['aav'].apply(format_value)\n",
    "    fa_cap_data['active_flag'] = 0\n",
    "\n",
    "    # Assuming df is your DataFrame and order is the desired column order\n",
    "    desired_order = [\n",
    "        'player_full_name', 'active_flag', 'team', 'age', 'signing_team', 'type', 'extension',\n",
    "        'arb_elig', 'arb_req', 'clause', 'signing', 'expiry', 'salary', 'base_salary',\n",
    "        'minors', 's_bonus', 'p_bonus', 'drafted', 'draft_round', 'draft_pick',\n",
    "        'draft_year', 'draft_team', 'signing_age', 'signing_date', 'length',\n",
    "        'exp_year', 'years_left', 'cap_hit', 'cap_hit_format', 'cap_hit_%', 'aav',\n",
    "        'aav_format', 'etl_insert_ts']\n",
    "\n",
    "    # Reorder the columns\n",
    "    fa_cap_data_clean = fa_cap_data[desired_order]\n",
    "    print(\"Free Agent player data scraped and stored as a pandas dataframe: fa_cap_data_clean.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -3- Union & Log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the datasets as CSVs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Append the dataframes together, then write as CSV locally\n",
    "all_player_data_clean = pd.concat([active_cap_data_clean, fa_cap_data_clean])\n",
    "all_player_data_raw = pd.concat([active_cap_data_clean, fa_cap_data])\n",
    "\n",
    "# Save the data to a CSV file\n",
    "all_player_data_raw.to_csv(\"capfriendly_data_raw.csv\", index=False) \n",
    "all_player_data_clean.to_csv(\"capfriendly_data_clean.csv\", index=False) \n",
    "print(f\"Wrote the datasets as CSVs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -4- Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-140-0dbb9df5527c>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ranks_data['player_name'] = ranks_data['player_name'].apply(replace_special_chars)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read ranks_data\n",
    "ranks_data_raw = pd.read_csv(\"../bq_results/202202_player_ranks.csv\")\n",
    "ranks_data = ranks_data_raw[ranks_data_raw['season_window'] == 'Last 3 seasons']\n",
    "\n",
    "# Function to replace special characters found in player_full_name\n",
    "def replace_special_chars(input_str):\n",
    "  special_chars = {\n",
    "      'á': 'a', 'Á': 'A', 'ä': 'a', 'Ä': 'A', 'é': 'e', 'É': 'E', 'è': 'e', 'È': 'E', 'ê': 'e', 'Ê': 'E',\n",
    "      'í': 'i', 'Í': 'I', 'ï': 'i', 'Ï': 'I', 'ó': 'o', 'Ó': 'O', 'ö': 'o', 'Ö': 'O', 'ô': 'o', 'Ô': 'O',\n",
    "      'ú': 'u', 'Ú': 'U', 'ü': 'u', 'Ü': 'U', 'û': 'u', 'Û': 'U', 'ñ': 'n', 'Ñ': 'N', 'ç': 'c', 'Ç': 'C',\n",
    "      'ß': 'ss', 'Æ': 'AE', 'æ': 'ae', 'Ø': 'O', 'ø': 'o', 'ł': 'l', 'Ł': 'L', 'ń': 'n', 'Ń': 'N',\n",
    "      'ś': 's', 'Ś': 'S', 'ć': 'c', 'Ć': 'C', 'ź': 'z', 'Ź': 'Z', 'ż': 'z', 'Ż': 'Z', 'ğ': 'g', 'Ğ': 'G',\n",
    "      'şı': 'si', 'Ş': 'Si', 'ķ': 'k', 'Ķ': 'K', 'š': 's', 'Š': 'S', 'č': 'c', 'Č': 'C', 'ž': 'z', 'Ž': 'Z',\n",
    "      'ň': 'n', 'Ň': 'N', 'ř': 'r', 'Ř': 'R', 'ý': 'y', 'Ý': 'Y', 'ů': 'u', 'Ů': 'U', 'ţ': 't', 'Ţ': 'T',\n",
    "      'ă': 'a', 'Ă': 'A', 'ş': 's', 'Ş': 'S', 'ď': 'd', 'Ď': 'D', 'ř': 'r', 'Ř': 'R', 'ť': 't', 'Ť': 'T',\n",
    "      'ĺ': 'l', 'Ĺ': 'L', 'ć': 'c', 'Ć': 'C', 'đ': 'd', 'Đ': 'D', 'ŕ': 'r', 'Ŕ': 'R', 'ľ': 'l', 'Ľ': 'L',\n",
    "      'ŝ': 's', 'Ŝ': 'S', 'ĥ': 'h', 'Ĥ': 'H', 'ĵ': 'j', 'Ĵ': 'J', 'ŵ': 'w', 'Ŵ': 'W', 'ŷ': 'y', 'Ŷ': 'Y',\n",
    "      'ẑ': 'z', 'Ẑ': 'Z', 'ơ': 'o', 'Ơ': 'O', 'ī': 'i', 'Ī': 'I', 'ū': 'u', 'Ū': 'U', 'ț': 't', 'Ț': 'T',\n",
    "      'ș': 's', 'Ș': 'S'\n",
    "  }\n",
    "    \n",
    "  # Use a regular expression to match and replace special characters\n",
    "  pattern = re.compile(\"|\".join(map(re.escape, special_chars.keys())))\n",
    "  return pattern.sub(lambda match: special_chars[match.group(0)], input_str)\n",
    "\n",
    "# Assuming you have a DataFrame named fa_cap_data\n",
    "ranks_data['player_name'] = ranks_data['player_name'].apply(replace_special_chars)\n",
    "\n",
    "# Write back as CSV\n",
    "ranks_data.to_csv(\"ranks_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of players: 937\n",
      "... after joining on name + team_code, we get + 571\n",
      "... after joining on name (alone), we get + 222\n",
      "... after joining on join_name (alone), we get + 36\n",
      "... in the end, we are left with  108\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to format player names\n",
    "def format_player_name(player_name):\n",
    "    name_parts = player_name.split()\n",
    "    if len(name_parts) >= 2:\n",
    "        first_initial = name_parts[0][0].upper()\n",
    "        last_name = name_parts[-1]\n",
    "        formatted_name = first_initial + ' ' + last_name\n",
    "    else:\n",
    "        formatted_name = player_name.replace('.', '')  # Remove dots if present\n",
    "    return formatted_name\n",
    "\n",
    "# Sample data for df1 and df2 (replace with your actual DataFrames)\n",
    "df1 = ranks_data.copy()\n",
    "df2 = pd.read_csv(\"capfriendly_data_clean.csv\")\n",
    "\n",
    "# Make a second player name key to join\n",
    "df1['join_player_name'] = df1['player_name'].apply(format_player_name)\n",
    "df2['join_player_name'] = df2['player_full_name'].apply(format_player_name)\n",
    "\n",
    "# Left join df1 to df2 on \"player_name\" = \"player_full_name\" and \"team_code\" = \"team_code\"\n",
    "merged_df1 = pd.merge(df1, df2[['player_full_name', 'team']], how='left', left_on=['player_name', 'current_team_code'], right_on=['player_full_name', 'team'], suffixes=('', '_1'))\n",
    "matched_df1 = merged_df1[merged_df1['player_full_name'].notnull()]\n",
    "unmatched_df1 = merged_df1[merged_df1['player_full_name'].isnull()]\n",
    "\n",
    "# Left join df1 to df2 on \"player_name\" = \"player_full_name\" and \"team_code\" = \"team_code\"\n",
    "merged_df2 = pd.merge(unmatched_df1, df2[['player_full_name']], how='left', left_on=['player_name'], right_on = ['player_full_name'], suffixes=('', '_2'))\n",
    "matched_df2 = merged_df2[merged_df2['player_full_name_2'].notnull()]\n",
    "unmatched_df2 = merged_df2[merged_df2['player_full_name_2'].isnull()]\n",
    "\n",
    "# Left join df1 to df2 on \"player_name\" = \"player_full_name\" and \"team_code\" = \"team_code\"\n",
    "merged_df3 = pd.merge(unmatched_df2, df2[['join_player_name', 'player_full_name']], how='left', left_on=['join_player_name'], right_on = ['join_player_name'], suffixes=('', '_3'))\n",
    "matched_df3 = merged_df3[merged_df3['player_full_name_3'].notnull()]\n",
    "unmatched_df3 = merged_df3[merged_df3['player_full_name_3'].isnull()]\n",
    "\n",
    "# Print it all out\n",
    "print(\"Total number of players:\", df1[\"player_id\"].nunique())\n",
    "print(\"... after joining on name + team_code, we get +\", matched_df1[\"player_id\"].nunique())\n",
    "print(\"... after joining on name (alone), we get +\", matched_df2[\"player_id\"].nunique())\n",
    "print(\"... after joining on join_name (alone), we get +\", matched_df3[\"player_id\"].nunique())\n",
    "print(\"... in the end, we are left with \", unmatched_df3[\"player_id\"].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
